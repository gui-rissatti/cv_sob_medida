"""
End-to-End Test Script - Simula intera√ß√£o completa do usu√°rio
Testa o fluxo: Frontend ‚Üí Backend ‚Üí LLM ‚Üí Response
"""
import sys
import os
import time
import json

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from app.main import app
from fastapi.testclient import TestClient

# Test data
TEST_URL = "https://www.linkedin.com/jobs/view/4341850331/?trk=mcm"
TEST_CV = """
JO√ÉO SILVA
S√£o Paulo, SP | joao.silva@email.com | (11) 98765-4321
LinkedIn: linkedin.com/in/joaosilva | GitHub: github.com/joaosilva

RESUMO PROFISSIONAL
Senior Data Analyst com 8+ anos de experi√™ncia em an√°lise de dados, engenharia de dados e business intelligence.
Especialista em constru√ß√£o de pipelines ETL, desenvolvimento de dashboards executivos e otimiza√ß√£o de performance.
Dom√≠nio de Python, SQL, Tableau e plataformas cloud (AWS, GCP).

EXPERI√äNCIA PROFISSIONAL

SENIOR DATA ANALYST | Tech Solutions Brasil | Jan 2019 - Presente
‚Ä¢ Liderei equipe de 5 analistas de dados, implementando best practices em visualiza√ß√£o e an√°lise
‚Ä¢ Constru√≠ pipelines ETL robustos processando 10M+ registros di√°rios com 99.9% de confiabilidade
‚Ä¢ Desenvolvi dashboards executivos no Tableau utilizados pelo C-level para tomada de decis√µes estrat√©gicas
‚Ä¢ Otimizei queries SQL reduzindo tempo de processamento em 60% atrav√©s de indexa√ß√£o e particionamento
‚Ä¢ Implementei processos de governan√ßa de dados garantindo qualidade e consist√™ncia
‚Ä¢ Colaborei com times de produto, engenharia e neg√≥cios em projetos de data-driven decision making

DATA ANALYST | Analytics Corp | Abr 2016 - Dez 2018
‚Ä¢ Criei relat√≥rios automatizados em Power BI reduzindo tempo de an√°lise em 40%
‚Ä¢ Desenvolvi modelos preditivos em Python para forecasting de vendas
‚Ä¢ Realizei an√°lises explorat√≥rias identificando oportunidades de otimiza√ß√£o de custos
‚Ä¢ Mantive documenta√ß√£o t√©cnica de processos e pipelines de dados

FORMA√á√ÉO ACAD√äMICA
Bacharelado em Ci√™ncia da Computa√ß√£o | USP | 2012 - 2015
MBA em Data Science e Analytics | FGV | 2017 - 2019

HABILIDADES T√âCNICAS
‚Ä¢ Linguagens: Python (Pandas, NumPy, Spark), SQL (PostgreSQL, MySQL)
‚Ä¢ Visualiza√ß√£o: Tableau, Power BI, Looker
‚Ä¢ Cloud: AWS (Redshift, S3, Lambda), GCP (BigQuery, Cloud Functions)
‚Ä¢ ETL/Orquestra√ß√£o: Airflow, dbt, Luigi
‚Ä¢ Big Data: Spark, Hadoop
‚Ä¢ Controle de Vers√£o: Git, GitHub
‚Ä¢ Banco de Dados: PostgreSQL, MySQL, MongoDB, Redshift, BigQuery

CERTIFICA√á√ïES
‚Ä¢ AWS Certified Data Analytics - Specialty
‚Ä¢ Google Cloud Professional Data Engineer
‚Ä¢ Tableau Desktop Specialist
"""

print("=" * 100)
print("TESTE END-TO-END COMPLETO - CV SOB MEDIDA")
print("=" * 100)

client = TestClient(app)

# Passo 1: Verificar sa√∫de do backend
print("\n[ETAPA 1/4] Verificando sa√∫de do backend...")
print("-" * 100)
health_response = client.get("/health")
assert health_response.status_code == 200, f"Health check failed: {health_response.status_code}"
print("‚úÖ Backend est√° saud√°vel e respondendo")

# Passo 2: Extrair detalhes da vaga
print("\n[ETAPA 2/4] Extraindo detalhes da vaga do LinkedIn...")
print(f"URL da vaga: {TEST_URL}")
print("-" * 100)

start_extraction = time.time()
extraction_response = client.post(
    "/extract-job-details",
    json={"url": TEST_URL},
    timeout=45.0
)
extraction_time = time.time() - start_extraction

assert extraction_response.status_code == 200, f"Extraction failed: {extraction_response.text}"
job_data = extraction_response.json()

print(f"‚úÖ Extra√ß√£o conclu√≠da em {extraction_time:.2f}s")
print(f"\nüìã DETALHES DA VAGA EXTRA√çDA:")
print(f"   ID: {job_data['id']}")
print(f"   T√≠tulo: {job_data['title']}")
print(f"   Empresa: {job_data['company']}")
print(f"   Skills identificadas: {len(job_data['skills'])}")
print(f"   Top 10 skills: {', '.join(job_data['skills'][:10])}")
print(f"   Descri√ß√£o (primeiros 200 chars): {job_data['description'][:200]}...")

# Passo 3: Gerar materiais personalizados
print("\n[ETAPA 3/4] Gerando materiais personalizados com IA...")
print("-" * 100)

start_generation = time.time()
generation_response = client.post(
    "/generate-materials",
    json={
        "job": {
            "id": job_data["id"],
            "title": job_data["title"],
            "company": job_data["company"],
            "description": job_data["description"],
            "skills": job_data["skills"]
        },
        "profile": {
            "cvText": TEST_CV
        }
    },
    timeout=90.0
)
generation_time = time.time() - start_generation

assert generation_response.status_code == 200, f"Generation failed: {generation_response.text}"
assets = generation_response.json()

print(f"‚úÖ Gera√ß√£o conclu√≠da em {generation_time:.2f}s")
print(f"\nüìÑ MATERIAIS GERADOS:")
print(f"   Match Score: {assets['matchScore']}/100")
print(f"   CV personalizado: {len(assets['cv'])} caracteres")
print(f"   Carta de apresenta√ß√£o: {len(assets['coverLetter'])} caracteres")
print(f"   Dicas de networking: {len(assets['networking'])} caracteres")

# Parse insights
try:
    insights = json.loads(assets['insights'])
    print(f"\nüéØ INSIGHTS DA AN√ÅLISE:")
    print(f"   Score: {insights['score']}/100")
    print(f"   For√ßas identificadas:")
    for i, strength in enumerate(insights['strengths'][:3], 1):
        print(f"      {i}. {strength[:100]}...")
    print(f"   Gap identificado: {insights['gap'][:150]}...")
except:
    print(f"   Insights: {assets['insights'][:200]}...")

# Passo 4: Validar qualidade dos outputs
print("\n[ETAPA 4/4] Validando qualidade dos outputs...")
print("-" * 100)

validations = []

# Valida√ß√£o 1: CV cont√©m keywords da vaga
job_keywords = set(word.lower() for word in job_data['skills'][:20])
cv_text = assets['cv'].lower()
keywords_found = sum(1 for keyword in job_keywords if keyword.lower() in cv_text)
keywords_percentage = (keywords_found / len(job_keywords)) * 100 if job_keywords else 0
validations.append(("CV cont√©m keywords da vaga", keywords_percentage >= 30, f"{keywords_percentage:.1f}%"))

# Valida√ß√£o 2: CV menciona a empresa
validations.append(("CV menciona a empresa", job_data['company'].lower() in cv_text, "Sim" if job_data['company'].lower() in cv_text else "N√£o"))

# Valida√ß√£o 3: Match score razo√°vel
validations.append(("Match score razo√°vel (>50)", assets['matchScore'] >= 50, f"{assets['matchScore']}/100"))

# Valida√ß√£o 4: Tamanho m√≠nimo dos documentos
validations.append(("CV tem tamanho adequado", len(assets['cv']) >= 500, f"{len(assets['cv'])} chars"))
validations.append(("Cover letter tem tamanho adequado", len(assets['coverLetter']) >= 500, f"{len(assets['coverLetter'])} chars"))

# Valida√ß√£o 5: Tempo de resposta aceit√°vel
total_time = extraction_time + generation_time
validations.append(("Tempo total aceit√°vel (<120s)", total_time < 120, f"{total_time:.2f}s"))

print("\nüìä RESULTADOS DAS VALIDA√á√ïES:")
all_passed = True
for validation_name, passed, detail in validations:
    status = "‚úÖ" if passed else "‚ùå"
    print(f"   {status} {validation_name}: {detail}")
    all_passed = all_passed and passed

# Resumo final
print("\n" + "=" * 100)
print("RESUMO DA EXECU√á√ÉO")
print("=" * 100)
print(f"‚è±Ô∏è  Tempo de extra√ß√£o: {extraction_time:.2f}s")
print(f"‚è±Ô∏è  Tempo de gera√ß√£o: {generation_time:.2f}s")
print(f"‚è±Ô∏è  Tempo total: {total_time:.2f}s")
print(f"üìä Valida√ß√µes passadas: {sum(1 for _, p, _ in validations if p)}/{len(validations)}")
print(f"üéØ Score de compatibilidade: {assets['matchScore']}/100")

if all_passed:
    print("\nüéâ TODOS OS TESTES PASSARAM! Sistema funcionando perfeitamente end-to-end!")
    sys.exit(0)
else:
    print("\n‚ö†Ô∏è  Algumas valida√ß√µes falharam. Revisar outputs acima.")
    sys.exit(1)
